{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "ocr = loadmat('ocr.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ocr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ocr['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ocr['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ocr['data'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ocr['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr['data'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr['data'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.T.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2]])\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ocr['data'][0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(ocr['data'][0],ocr['data'][0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import loadmat\n",
    "from random import sample\n",
    "import numpy as np\n",
    "\n",
    "def nn(X,Y,test):\n",
    "    \n",
    "    x2 = np.square(X).sum(axis = 1)                                     \n",
    "    xt = np.dot(test,X.T)\n",
    "    t2 = np.transpose(np.square(test).sum(axis = 1)[np.newaxis]) \n",
    "    dist = x2 - 2*xt + t2\n",
    "    preds = Y[np.argmin(dist, axis = 1)]\n",
    "    return preds\n",
    "\n",
    "def find():\n",
    "    ocr = loadmat('ocr.mat')\n",
    "    num_trials = 10\n",
    "    for n in [ 1000, 2000, 4000, 8000 ]:\n",
    "        test_err = np.zeros(num_trials)\n",
    "        for trial in range(num_trials):\n",
    "            sel = sample(range(len(ocr['data'].astype('float'))),n)\n",
    "            preds = nn(ocr['data'].astype('float')[sel], ocr['labels'][sel], ocr['testdata'].astype('float'))\n",
    "            test_err[trial] = np.mean(preds != ocr['testlabels'])\n",
    "        print(\"%d\\t%g\\t%g\" % (n,np.mean(test_err),np.std(test_err)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t0.11265\t0.00413358\n",
      "2000\t0.08839\t0.00215009\n",
      "4000\t0.06874\t0.00292411\n",
      "8000\t0.05622\t0.000837616\n"
     ]
    }
   ],
   "source": [
    "find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import loadmat\n",
    "from random import sample\n",
    "import numpy as np\n",
    "\n",
    "def nn(X,Y,test):\n",
    "                                         \n",
    "    distance1 = np.transpose(np.sum(test*test, axis = 1)[np.newaxis])\n",
    "    distance2 = np.dot(test,X.T)\n",
    "    distance3 = np.sum(X*X, axis = 1)\n",
    "    distance = distance1 - 2*distance2 + distance3\n",
    "    preds = Y[np.argmin(distance, axis = 1)]\n",
    "    return preds\n",
    "\n",
    "def find():\n",
    "    ocr = loadmat('ocr.mat')\n",
    "    num_trials = 10\n",
    "    for n in [ 1000, 2000, 4000, 8000 ]:\n",
    "        test_err = np.zeros(num_trials)\n",
    "        for trial in range(num_trials):\n",
    "            sel = sample(range(len(ocr['data'].astype('float'))),n)\n",
    "            preds = nn(ocr['data'].astype('float')[sel], ocr['labels'][sel], ocr['testdata'].astype('float'))\n",
    "            test_err[trial] = np.mean(preds != ocr['testlabels'])\n",
    "        print(\"%d\\t%g\\t%g\" % (n,np.mean(test_err),np.std(test_err)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t0.1166\t0.00419714\n",
      "2000\t0.09163\t0.0028164\n",
      "4000\t0.06899\t0.00250178\n",
      "8000\t0.05672\t0.00155035\n"
     ]
    }
   ],
   "source": [
    "find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "    # 20-way classification problem\n",
    "news = loadmat('news.mat')\n",
    "data = news['data']\n",
    "labels = news['labels'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11)\t1.0\n",
      "  (0, 22)\t1.0\n",
      "  (0, 24)\t1.0\n",
      "  (0, 26)\t1.0\n",
      "  (0, 28)\t1.0\n",
      "  (0, 29)\t1.0\n",
      "  (0, 30)\t1.0\n",
      "  (0, 32)\t1.0\n",
      "  (0, 41)\t1.0\n",
      "  (0, 43)\t1.0\n",
      "  (0, 50)\t1.0\n",
      "  (0, 51)\t1.0\n",
      "  (0, 59)\t1.0\n",
      "  (0, 66)\t1.0\n",
      "  (0, 71)\t1.0\n",
      "  (0, 75)\t1.0\n",
      "  (0, 79)\t1.0\n",
      "  (0, 82)\t1.0\n",
      "  (0, 103)\t1.0\n",
      "  (0, 138)\t1.0\n",
      "  (0, 141)\t1.0\n",
      "  (0, 143)\t1.0\n",
      "  (0, 232)\t1.0\n",
      "  (0, 250)\t1.0\n",
      "  (0, 276)\t1.0\n",
      "  :\t:\n",
      "  (0, 1352)\t1.0\n",
      "  (0, 1365)\t1.0\n",
      "  (0, 1416)\t1.0\n",
      "  (0, 1453)\t1.0\n",
      "  (0, 1480)\t1.0\n",
      "  (0, 1481)\t1.0\n",
      "  (0, 1544)\t1.0\n",
      "  (0, 1742)\t1.0\n",
      "  (0, 1812)\t1.0\n",
      "  (0, 1953)\t1.0\n",
      "  (0, 2211)\t1.0\n",
      "  (0, 2223)\t1.0\n",
      "  (0, 2248)\t1.0\n",
      "  (0, 2249)\t1.0\n",
      "  (0, 2250)\t1.0\n",
      "  (0, 2251)\t1.0\n",
      "  (0, 2252)\t1.0\n",
      "  (0, 2253)\t1.0\n",
      "  (0, 2254)\t1.0\n",
      "  (0, 2255)\t1.0\n",
      "  (0, 2256)\t1.0\n",
      "  (0, 2257)\t1.0\n",
      "  (0, 2258)\t1.0\n",
      "  (0, 2259)\t1.0\n",
      "  (0, 2260)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(data[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11269\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_x = []\n",
    "for i in range(1,21):\n",
    "    for idx, elem in enumerate(labels):\n",
    "        if elem == i:\n",
    "            list_x.append(data[idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_list = []   \n",
    "for i in range(1,21):\n",
    "    idx = [idx for idx, e in enumerate(labels) if e==i]\n",
    "    sp_list.append(data[idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11269, 61188)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csc.csc_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sp_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "darray = sp_list[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(darray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(darray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 classes: training error rate: 0.216257\n",
      "20 classes: test error rate: 0.376016\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-94267d22d50a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mlabels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mlabels2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/csc.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Use CSR to implement fancy indexing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Things that return submatrices. row or col is a int or slice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         if (isinstance(row, slice) or isinstance(col, slice) or\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36m_unpack_index\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Next, check for validity, or transform the index as needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36m_check_boolean\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \"are equal shapes.\")\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boolean_index_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boolean_index_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36m_boolean_index_to_array\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_boolean_index_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid index shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index shape"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def estimate_naive_bayes_classifier(X,Y,yn):\n",
    "    '''divide X into yn classes'''\n",
    "    list_x = []\n",
    "    for i in range(1,yn+1):\n",
    "        idx = [idx for idx, elem in enumerate(Y) if elem == i]\n",
    "        list_x.append(X[idx,:])\n",
    "\n",
    "    '''count mu and pi'''\n",
    "    n,d = X.shape\n",
    "    mu = np.zeros((yn,d))\n",
    "    pi = np.zeros((yn,1))\n",
    "\n",
    "    for i in range(0,yn):\n",
    "        darray = list_x[i].toarray()\n",
    "        sumx = np.sum(darray, axis = 0)\n",
    "        piy = darray.shape[0]\n",
    "        mu[i,:] = np.divide((1+sumx),(2+piy))\n",
    "        pi[i,0] = np.divide(float(piy),float(yn))\n",
    "\n",
    "    return (mu,pi)\n",
    "\n",
    "\n",
    "def predict(params,X,yn):\n",
    "    mu = params[0]\n",
    "    pi = params[1]\n",
    "\n",
    "    (n,d) = X.shape\n",
    "    pred_matrix = np.zeros((n,yn))\n",
    "   \n",
    "    #count 1-X, as X is sparse matrix\n",
    "    data_X = np.tile([1],(n,d)) - X\n",
    "    pred_matrix = np.log(mu)*X.T + np.log(1 - mu)*data_X.T\n",
    "    pred_mt = np.zeros((yn,n))\n",
    "    for i in range(yn):\n",
    "        pred_mt[i,:] = np.log(pi[i,0]) + pred_matrix[i,:]\n",
    "\n",
    "    pred = np.zeros((n,1))\n",
    "    pred[:,0] = np.argmax(pred_mt,axis=0)\n",
    "    pred = pred + 1\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    return loadmat('news.mat')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    news = load_data()\n",
    "\n",
    "    # 20-way classification problem\n",
    "\n",
    "    data = news['data']\n",
    "    labels = news['labels']\n",
    "    testdata = news['testdata']\n",
    "    testlabels = news['testlabels']\n",
    "    params = estimate_naive_bayes_classifier(data,labels,20)\n",
    "    pred = predict(params,data,20) # predictions on training data\n",
    "    testpred = predict(params,testdata,20) # predictions on test data\n",
    "\n",
    "    print('20 classes: training error rate: %g' % np.mean(pred != labels))\n",
    "    print('20 classes: test error rate: %g' % np.mean(testpred != testlabels))\n",
    "    \n",
    "    indices = (labels==1) | (labels==16) | (labels==20) | (labels==17) | (labels==18) | (labels==19)\n",
    "    data2 = data[indices,:]\n",
    "    labels2 = labels[indices]\n",
    "    labels2[(labels2==1) | (labels2==16) | (labels2==20)] = 0\n",
    "    labels2[(labels2==17) | (labels2==18) | (labels2==19)] = 1\n",
    "    testindices = (testlabels==1) | (testlabels==16) | (testlabels==20) | (testlabels==17) | (testlabels==18) | (testlabels==19)\n",
    "    testdata2 = testdata[testindices,:]\n",
    "    testlabels2 = testlabels[testindices]\n",
    "    testlabels2[(testlabels2==1) | (testlabels2==16) | (testlabels2==20)] = 0\n",
    "    testlabels2[(testlabels2==17) | (testlabels2==18) | (testlabels2==19)] = 1\n",
    "\n",
    "    params2 = estimate_naive_bayes_classifier(data2,labels2,2)\n",
    "    pred2 = predict(params2,data2,2) # predictions on training data\n",
    "    testpred2 = predict(params2,testdata2,2) # predictions on test data\n",
    "\n",
    "    print('2 classes: training error rate: %g' % np.mean(pred2 != labels2))\n",
    "    print('2 classes: test error rate: %g' % np.mean(testpred2 != testlabels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def estimate_naive_bayes_classifier(X,Y,yn):\n",
    "    '''divide X into yn classes'''\n",
    "    list_x = []\n",
    "    for i in range(0,yn):\n",
    "        idx = [idx for idx, elem in enumerate(Y) if elem == i]\n",
    "        list_x.append(X[idx,:])\n",
    "\n",
    "    '''count mu and pi'''\n",
    "    n,d = X.shape\n",
    "    mu = np.zeros((yn,d))\n",
    "    pi = np.zeros((yn,1))\n",
    "\n",
    "    for i in range(0,yn):\n",
    "        darray = list_x[i]\n",
    "        sumx = np.sum(darray, axis = 0)\n",
    "        piy = darray.shape[0]\n",
    "        mu[i,:] = np.divide((1+sumx),(2+piy))\n",
    "        pi[i,0] = np.divide(float(piy),float(yn))\n",
    "\n",
    "    return (mu,pi)\n",
    "\n",
    "\n",
    "def predict(params,X,yn):\n",
    "    mu = params[0]\n",
    "    pi = params[1]\n",
    "\n",
    "    (n,d) = X.shape\n",
    "    pred_matrix = np.zeros((n,yn))\n",
    "   \n",
    "    #count 1-X, as X is sparse matrix\n",
    "    data_X = np.tile([1],(n,d)) - X\n",
    "    pred_matrix = np.log(mu)*X.T + np.log(1 - mu)*data_X.T\n",
    "    pred_mt = np.zeros((yn,n))\n",
    "    for i in range(yn):\n",
    "        pred_mt[i,:] = np.log(pi[i,0]) + pred_matrix[i,:]\n",
    "\n",
    "    pred = np.zeros((n,1))\n",
    "    pred[:,0] = np.argmax(pred_mt,axis=0)\n",
    "    pred = pred + 1\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    return loadmat('news.mat')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    news = load_data()\n",
    "\n",
    "    # 20-way classification problem\n",
    "\n",
    "    data = news['data']\n",
    "    labels = news['labels']\n",
    "    testdata = news['testdata']\n",
    "    testlabels = news['testlabels']\n",
    "#     params = estimate_naive_bayes_classifier(data,labels,20)\n",
    "#     pred = predict(params,data,20) # predictions on training data\n",
    "#     testpred = predict(params,testdata,20) # predictions on test data\n",
    "\n",
    "#     print('20 classes: training error rate: %g' % np.mean(pred != labels))\n",
    "#     print('20 classes: test error rate: %g' % np.mean(testpred != testlabels))\n",
    "    \n",
    "    indices = (labels==1) | (labels==16) | (labels==20) | (labels==17) | (labels==18) | (labels==19)\n",
    "    data2 = data[indices,:]\n",
    "    #data2 =  data[np.where((labels == 1) | (labels==16) | (labels==20) | (labels==17) | (labels==18) | (labels==19))[0]]\n",
    "    \n",
    "    labels2 = labels[indices]\n",
    "    labels2[(labels2==1) | (labels2==16) | (labels2==20)] = 0\n",
    "    labels2[(labels2==17) | (labels2==18) | (labels2==19)] = 1\n",
    "    testindices = (testlabels==1) | (testlabels==16) | (testlabels==20) | (testlabels==17) | (testlabels==18) | (testlabels==19)\n",
    "    \n",
    "    testdata2 = data[testindices,:]\n",
    "    #testdata2 = testdata[np.where((testlabels==1) | (testlabels==16) | (testlabels==20) | (testlabels==17) | (testlabels==18) | (testlabels==19))]\n",
    "    testlabels2 = testlabels[testindices]\n",
    "    testlabels2[(testlabels2==1) | (testlabels2==16) | (testlabels2==20)] = 0\n",
    "    testlabels2[(testlabels2==17) | (testlabels2==18) | (testlabels2==19)] = 1\n",
    "\n",
    "    params2 = estimate_naive_bayes_classifier(data2,labels2,2)\n",
    "    pred2 = predict(params2,data2,2) # predictions on training data\n",
    "    testpred2 = predict(params2,testdata2,2) # predictions on test data\n",
    "\n",
    "    print('2 classes: training error rate: %g' % np.mean(pred2 != labels2))\n",
    "    print('2 classes: test error rate: %g' % np.mean(testpred2 != testlabels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 classes: training error rate: 0.72619\n",
      "2 classes: test error rate: 0.700095\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def estimate_naive_bayes_classifier(X,Y):\n",
    "    '''divide X into 2 classes'''\n",
    "    list_x = []\n",
    "    for i in range(0,2):\n",
    "        idx = [idx for idx, elem in enumerate(Y) if elem == i]\n",
    "        list_x.append(X[idx,:])\n",
    "\n",
    "    '''count mu and pi'''\n",
    "    n,d = X.shape\n",
    "    mu = np.zeros((2,d))\n",
    "    pi = np.zeros((2,1))\n",
    "\n",
    "    for i in range(0,2):\n",
    "        darray = list_x[i].toarray()\n",
    "        sumx = np.sum(darray, axis = 0)\n",
    "        piy = darray.shape[0]\n",
    "        mu[i,:] = np.divide((1+sumx),(2+piy))\n",
    "        pi[i,0] = np.divide(float(piy),float(2))\n",
    "\n",
    "    return (mu,pi)\n",
    "\n",
    "\n",
    "def predict(params,X):\n",
    "    mu = params[0]\n",
    "    pi = params[1]\n",
    "\n",
    "    (n,d) = X.shape\n",
    "    pred_matrix = np.zeros((n,2))\n",
    "   \n",
    "    #count 1-X, as X is sparse matrix\n",
    "    data_X = np.tile([1],(n,d)) - X\n",
    "    pred_matrix = np.log(mu)*X.T + np.log(1 - mu)*data_X.T\n",
    "    pred_mt = np.zeros((2,n))\n",
    "    for i in range(2):\n",
    "        pred_mt[i,:] = np.log(pi[i,0]) + pred_matrix[i,:]\n",
    "\n",
    "    pred = np.zeros((n,1))\n",
    "    pred[:,0] = np.argmax(pred_mt,axis=0)\n",
    "    pred = pred + 1\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    return loadmat('news.mat')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    news = load_data()\n",
    "\n",
    "    # 20-way classification problem\n",
    "\n",
    "    data = news['data']\n",
    "    labels = news['labels'][:,0]\n",
    "    testdata = news['testdata']\n",
    "    testlabels = news['testlabels'][:,0]\n",
    "\n",
    "    params = estimate_naive_bayes_classifier(data,labels)\n",
    "    pred = predict(params,data) # predictions on training data\n",
    "    testpred = predict(params,testdata) # predictions on test data\n",
    "\n",
    "    print('20 classes: training error rate: %g' % np.mean(pred != labels))\n",
    "    print('20 classes: test error rate: %g' % np.mean(testpred != testlabels))\n",
    "    # binary classification problem\n",
    "\n",
    "#     indices = (labels==1) | (labels==16) | (labels==20) | (labels==17) | (labels==18) | (labels==19)\n",
    "#     data2 = data[indices,:]\n",
    "#     labels2 = labels[indices]\n",
    "#     labels2[(labels2==1) | (labels2==16) | (labels2==20)] = 0\n",
    "#     labels2[(labels2==17) | (labels2==18) | (labels2==19)] = 1\n",
    "#     testindices = (testlabels==1) | (testlabels==16) | (testlabels==20) | (testlabels==17) | (testlabels==18) | (testlabels==19)\n",
    "#     testdata2 = testdata[testindices,:]\n",
    "#     testlabels2 = testlabels[testindices]\n",
    "#     testlabels2[(testlabels2==1) | (testlabels2==16) | (testlabels2==20)] = 0\n",
    "#     testlabels2[(testlabels2==17) | (testlabels2==18) | (testlabels2==19)] = 1\n",
    "\n",
    "#     params2 = estimate_naive_bayes_classifier(data2,labels2)\n",
    "#     pred2 = predict(params2,data2) # predictions on training data\n",
    "#     testpred2 = predict(params2,testdata2) # predictions on test data\n",
    "\n",
    "#     print('2 classes: training error rate: %g' % np.mean(pred2 != labels2))\n",
    "#     print('2 classes: test error rate: %g' % np.mean(testpred2 != testlabels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 classes: training error rate: 0.948825\n",
      "20 classes: test error rate: 0.948556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 classes: training error rate: 0.480515\n",
      "2 classes: test error rate: 0.479425\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def estimate_naive_bayes_classifier(X,Y):\n",
    "    '''divide X into 20 classes'''\n",
    "    list_x = []\n",
    "    for i in range(1,21):\n",
    "        idx = [idx for idx, elem in enumerate(Y) if elem == i]\n",
    "        list_x.append(X[idx,:])\n",
    "\n",
    "    '''count mu and pi'''\n",
    "    n,d = X.shape\n",
    "    mu = np.zeros((20,d))\n",
    "    pi = np.zeros((20,1))\n",
    "\n",
    "    for i in range(0,20):\n",
    "        darray = list_x[i].toarray()\n",
    "        sumx = np.sum(darray, axis = 0)\n",
    "        piy = darray.shape[0]\n",
    "        mu[i,:] = np.divide((1+sumx),(2+piy))\n",
    "        pi[i,0] = np.divide(float(piy),float(20))\n",
    "\n",
    "    return (mu,pi)\n",
    "\n",
    "\n",
    "def predict(params,X):\n",
    "    mu = params[0]\n",
    "    pi = params[1]\n",
    "\n",
    "    (n,d) = X.shape\n",
    "    pred_matrix = np.zeros((n,20))\n",
    "   \n",
    "    #count 1-X, as X is sparse matrix\n",
    "    data_X = np.tile([1],(n,d)) - X\n",
    "    pred_matrix = np.log(mu)*X.T + np.log(1 - mu)*data_X.T\n",
    "    pred_mt = np.zeros((20,n))\n",
    "    for i in range(20):\n",
    "        pred_mt[i,:] = np.log(pi[i,0]) + pred_matrix[i,:]\n",
    "\n",
    "    pred = np.zeros((n,1))\n",
    "    pred[:,0] = np.argmax(pred_mt,axis=0)\n",
    "    pred = pred + 1\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def print_top_words(params,vocab):\n",
    "    raise Exception(\"IMPLEMENT ME\")\n",
    "\n",
    "def load_data():\n",
    "    return loadmat('news.mat')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    news = load_data()\n",
    "\n",
    "    # 20-way classification problem\n",
    "\n",
    "    data = news['data']\n",
    "    labels = news['labels'][:,0]\n",
    "    testdata = news['testdata']\n",
    "    testlabels = news['testlabels'][:,0]\n",
    "\n",
    "    params = estimate_naive_bayes_classifier(data,labels)\n",
    "    pred = predict(params,data) # predictions on training data\n",
    "    testpred = predict(params,testdata) # predictions on test data\n",
    "\n",
    "    print('20 classes: training error rate: %g' % np.mean(pred != labels))\n",
    "    print('20 classes: test error rate: %g' % np.mean(testpred != testlabels))\n",
    "\n",
    "    # binary classification problem\n",
    "\n",
    "    indices = (labels==1) | (labels==16) | (labels==20) | (labels==17) | (labels==18) | (labels==19)\n",
    "    data2 = data[indices,:]\n",
    "    labels2 = labels[indices]\n",
    "    labels2[(labels2==1) | (labels2==16) | (labels2==20)] = 0\n",
    "    labels2[(labels2==17) | (labels2==18) | (labels2==19)] = 1\n",
    "    testindices = (testlabels==1) | (testlabels==16) | (testlabels==20) | (testlabels==17) | (testlabels==18) | (testlabels==19)\n",
    "    testdata2 = testdata[testindices,:]\n",
    "    testlabels2 = testlabels[testindices]\n",
    "    testlabels2[(testlabels2==1) | (testlabels2==16) | (testlabels2==20)] = 0\n",
    "    testlabels2[(testlabels2==17) | (testlabels2==18) | (testlabels2==19)] = 1\n",
    "\n",
    "    params2 = estimate_naive_bayes_classifier(data2,labels2)\n",
    "    pred2 = predict(params2,data2) # predictions on training data\n",
    "    testpred2 = predict(params2,testdata2) # predictions on test data\n",
    "\n",
    "    print('2 classes: training error rate: %g' % np.mean(pred2 != labels2))\n",
    "    print('2 classes: test error rate: %g' % np.mean(testpred2 != testlabels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11269, 61188)\n",
      "data2  (3028, 61188)\n",
      "labels2,  (3028, 1)\n",
      "mu (2, 61188)\n",
      "pi (2, 1)\n",
      "data_X.T (61188, 3028)\n",
      "data_X (3028, 61188)\n",
      "X.T (61188, 3028)\n",
      "mu (2, 61188)\n",
      "1-mu (2, 61188)\n",
      "np.log(mu)*X.T (2, 3028)\n",
      "np.log(1 - mu)*data_X.T (2, 3028)\n",
      "2 classes: training error rate: 0.0577939\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def estimate_naive_bayes_classifier(X,Y,yn):\n",
    "    '''divide X into yn classes'''\n",
    "    list_x = []\n",
    "    for i in range(1,yn+1):\n",
    "        idx = [idx for idx, elem in enumerate(Y) if elem == i]\n",
    "        list_x.append(X[idx,:])\n",
    "\n",
    "    '''count mu and pi'''\n",
    "    n,d = X.shape\n",
    "    mu = np.zeros((yn,d))\n",
    "    pi = np.zeros((yn,1))\n",
    "\n",
    "    for i in range(0,yn):\n",
    "        darray = list_x[i]\n",
    "        sumx = np.sum(darray, axis = 0)\n",
    "        piy = darray.shape[0]\n",
    "        mu[i,:] = np.divide((1+sumx),(2+piy))\n",
    "        pi[i,0] = np.divide(float(piy),float(yn))\n",
    "\n",
    "    return (mu,pi)\n",
    "\n",
    "\n",
    "def predict(params,X,yn):\n",
    "    mu = params[0]\n",
    "    pi = params[1]\n",
    "\n",
    "    (n,d) = X.shape\n",
    "    pred_matrix = np.zeros((n,yn))\n",
    "   \n",
    "    #count 1-X, as X is sparse matrix\n",
    "    data_X = np.tile([1],(n,d)) - X\n",
    "    print(\"data_X.T\",data_X.T.shape)\n",
    "    print(\"data_X\",data_X.shape)\n",
    "    print(\"X.T\",X.T.shape)\n",
    "    print(\"mu\",np.log(mu).shape)\n",
    "    print(\"1-mu\",np.log(1-mu).shape)\n",
    "    print(\"np.log(mu)*X.T\",np.matmul(np.log(mu),X.T).shape)\n",
    "    print(\"np.log(1 - mu)*data_X.T\",(np.matmul(np.log(1 - mu),data_X.T)).shape)\n",
    "    pred_matrix = np.matmul(np.log(mu),X.T) + np.matmul(np.log(1 - mu),data_X.T)\n",
    "    pred_mt = np.zeros((yn,n))\n",
    "    for i in range(yn):\n",
    "        pred_mt[i,:] = np.log(pi[i,0]) + pred_matrix[i,:]\n",
    "\n",
    "    pred = np.zeros((n,1))\n",
    "    pred[:,0] = np.argmax(pred_mt,axis=0)\n",
    "    pred = pred + 1\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    return loadmat('news.mat')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    news = load_data()\n",
    "\n",
    "    # 20-way classification problem\n",
    "\n",
    "    data = news['data']\n",
    "    labels = news['labels']\n",
    "    testdata = news['testdata']\n",
    "    testlabels = news['testlabels']\n",
    "    \n",
    "    #print(type(labels))\n",
    "    #print(labels[0:5])\n",
    "    #print(type(data))\n",
    "    data = data.toarray()\n",
    "    print(data.shape)\n",
    "    \n",
    "    \n",
    "    #params = estimate_naive_bayes_classifier(data,labels,20)\n",
    "    #pred = predict(params,data,20) # predictions on training data\n",
    "    #testpred = predict(params,testdata,20) # predictions on test data\n",
    "\n",
    "    #print('20 classes: training error rate: %g' % np.mean(pred != labels))\n",
    "    #print('20 classes: test error rate: %g' % np.mean(testpred != testlabels))\n",
    "    \n",
    "    indices = (labels==1) | (labels==16) | (labels==20) | (labels==17) | (labels==18) | (labels==19)\n",
    "#     data2 =  data[np.where((labels == 1) | (labels==16) | (labels==20) | (labels==17) | (labels==18) | (labels==19))[0]]\n",
    "#     labels2 = labels[np.where((labels==1) | (labels==16) | (labels==20) | (labels==17) | (labels==18) | (labels==19))]\n",
    "\n",
    "#     labels2[(labels2==1) | (labels2==16) | (labels2==20)] = 1\n",
    "#     labels2[(labels2==17) | (labels2==18) | (labels2==19)] = 2\n",
    "#     params2 = estimate_naive_bayes_classifier(data2,labels2,2)\n",
    "#     pred2 = predict(params2,data2,2) # predictions on training data\n",
    "\n",
    "\n",
    "#     print('2 classes: training error rate: %g' % np.mean(pred2 != labels2))\n",
    "    #print(indices.shape)\n",
    "    indices = np.reshape(indices, 11269)\n",
    "    \n",
    "    data2 = data[indices,:]\n",
    "    print(\"data2 \", data2.shape)\n",
    "    labels2 = labels[indices]\n",
    "    labels2[(labels2==1) | (labels2==16) | (labels2==20)] = 1\n",
    "    labels2[(labels2==17) | (labels2==18) | (labels2==19)] = 2\n",
    "    print(\"labels2, \", labels2.shape)\n",
    "#     testindices = (testlabels==1) | (testlabels==16) | (testlabels==20) | (testlabels==17) | (testlabels==18) | (testlabels==19)\n",
    "#     testdata2 = testdata[testindices]\n",
    "#     testlabels2 = testlabels[testindices]\n",
    "#     testlabels2[(testlabels2==1) | (testlabels2==16) | (testlabels2==20)] = 1\n",
    "#     testlabels2[(testlabels2==17) | (testlabels2==18) | (testlabels2==19)] = 2\n",
    "\n",
    "    params2 = estimate_naive_bayes_classifier(data2,labels2,2)\n",
    "    print(\"mu\",params2[0].shape)\n",
    "    print(\"pi\",params2[1].shape)\n",
    "    pred2 = predict(params2,data2,2) # predictions on training data\n",
    "    #testpred2 = predict(params2,testdata2,2) # predictions on test data\n",
    "    print('2 classes: training error rate: %g' % np.mean(pred2 != labels2))\n",
    "#     print('2 classes: test error rate: %g' % np.mean(testpred2 != testlabels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11269, 61188)\n",
      "(11269, 1)\n",
      "(3028, 61188)\n",
      "(3028,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "print(data2.shape)\n",
    "print(labels2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9a0e7aa419f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "labels = np.asarray([[0],[1],[1],[0]])\n",
    "data = np.asarray([[0,0,0],[1,1,1],[2,2,2],[3,3,3]])\n",
    "indices = (labels == 1)\n",
    "labels2 = labels[indices]\n",
    "data2 = data[indices,:]\n",
    "print(indices)\n",
    "print(type(indices))\n",
    "print(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 classes: training error rate: 0.0577939\n",
      "2 classes: test error rate: 0.131383\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def estimate_naive_bayes_classifier(X,Y,yn):\n",
    "    '''divide X into yn classes'''\n",
    "    list_x = []\n",
    "    for i in range(1,yn+1):\n",
    "        idx = [idx for idx, elem in enumerate(Y) if elem == i]\n",
    "        list_x.append(X[idx,:])\n",
    "\n",
    "    '''count mu and pi'''\n",
    "    n,d = X.shape\n",
    "    mu = np.zeros((yn,d))\n",
    "    pi = np.zeros((yn,1))\n",
    "\n",
    "    for i in range(0,yn):\n",
    "        darray = list_x[i]\n",
    "        sumx = np.sum(darray, axis = 0)\n",
    "        piy = darray.shape[0]\n",
    "        mu[i,:] = np.divide((1+sumx),(2+piy))\n",
    "        pi[i,0] = np.divide(float(piy),float(yn))\n",
    "\n",
    "    return (mu,pi)\n",
    "\n",
    "\n",
    "def predict(params,X,yn):\n",
    "    mu = params[0]\n",
    "    pi = params[1]\n",
    "\n",
    "    (n,d) = X.shape\n",
    "    pred_matrix = np.zeros((n,yn))\n",
    "   \n",
    "    #count 1-X, as X is sparse matrix\n",
    "    data_X = np.tile([1],(n,d)) - X\n",
    "    pred_matrix = np.matmul(np.log(mu),X.T) + np.matmul(np.log(1 - mu),data_X.T)\n",
    "    pred_mt = np.zeros((yn,n))\n",
    "    for i in range(yn):\n",
    "        pred_mt[i,:] = np.log(pi[i,0]) + pred_matrix[i,:]\n",
    "\n",
    "    pred = np.zeros((n,1))\n",
    "    pred[:,0] = np.argmax(pred_mt,axis=0)\n",
    "    pred = pred + 1\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    return loadmat('news.mat')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    news = load_data()\n",
    "    # 20-way classification problem\n",
    "\n",
    "    data = news['data']\n",
    "    labels = news['labels']\n",
    "    testdata = news['testdata']\n",
    "    testlabels = news['testlabels']\n",
    "    \n",
    "    data = data.toarray()\n",
    "    testdata = testdata.toarray()\n",
    "#     print(data.shape)\n",
    "#     print(labels.shape)\n",
    "#     print(params.shape)\n",
    "    params = estimate_naive_bayes_classifier(data,labels,20)\n",
    "    pred = predict(params,data,20) # predictions on training data\n",
    "    testpred = predict(params,testdata,20) # predictions on test data\n",
    "\n",
    "    print('20 classes: training error rate: %g' % np.mean(pred != labels))\n",
    "    print('20 classes: test error rate: %g' % np.mean(testpred != testlabels))\n",
    "    \n",
    "    (ntrain,dtrain) = data.shape\n",
    "    (ntest,dtest) = testdata.shape\n",
    "    \n",
    "    # 2 classes\n",
    "    indices = (labels==1) | (labels==16) | (labels==20) | (labels==17) | (labels==18) | (labels==19)  \n",
    "    indices = np.reshape(indices, ntrain)\n",
    "    data2 = data[indices,:]\n",
    "    labels2 = labels[indices]\n",
    "    labels2[(labels2==1) | (labels2==16) | (labels2==20)] = 1\n",
    "    labels2[(labels2==17) | (labels2==18) | (labels2==19)] = 2\n",
    "    \n",
    "    testindices = (testlabels==1) | (testlabels==16) | (testlabels==20) | (testlabels==17) | (testlabels==18) | (testlabels==19)\n",
    "    testindices = np.reshape(testindices, ntest)\n",
    "    testdata2 = testdata[testindices,:]\n",
    "    testlabels2 = testlabels[testindices]\n",
    "    testlabels2[(testlabels2==1) | (testlabels2==16) | (testlabels2==20)] = 1\n",
    "    testlabels2[(testlabels2==17) | (testlabels2==18) | (testlabels2==19)] = 2\n",
    "\n",
    "    params2 = estimate_naive_bayes_classifier(data2,labels2,2)\n",
    "    pred2 = predict(params2,data2,2) # predictions on training data\n",
    "    testpred2 = predict(params2,testdata2,2) # predictions on test data\n",
    "    print('2 classes: training error rate: %g' % np.mean(pred2 != labels2))\n",
    "    print('2 classes: test error rate: %g' % np.mean(testpred2 != testlabels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "largest words are ['firearms', 'occupied', 'israelis', 'argic', 'serdar', 'melkonian', 'sahak', 'appressian', 'ohanus', 'villages', 'cramer', 'armenia', 'cpr', 'sdpa', 'palestine', 'optilink', 'handgun', 'firearm', 'budget', 'arabs']\n",
      "smallest words are ['prophet', 'mozumder', 'jesus', 'benedikt', 'ksand', 'alink', 'believers', 'theology', 'scriptures', 'wpd', 'solntze', 'atheist', 'livesey', 'testament', 'revelation', 'teachings', 'clh', 'atheists', 'atheism', 'athos']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def estimate_naive_bayes_classifier(X,Y,yn):\n",
    "    '''divide X into yn classes'''\n",
    "    list_x = []\n",
    "    for i in range(1,yn+1):\n",
    "        idx = [idx for idx, elem in enumerate(Y) if elem == i]\n",
    "        list_x.append(X[idx,:])\n",
    "\n",
    "    '''count mu and pi'''\n",
    "    n,d = X.shape\n",
    "    mu = np.zeros((yn,d))\n",
    "    pi = np.zeros((yn,1))\n",
    "\n",
    "    for i in range(0,yn):\n",
    "        darray = list_x[i]\n",
    "        sumx = np.sum(darray, axis = 0)\n",
    "        piy = darray.shape[0]\n",
    "        mu[i,:] = np.divide((1+sumx),(2+piy))\n",
    "        pi[i,0] = np.divide(float(piy),float(yn))\n",
    "\n",
    "    return (mu,pi)\n",
    "\n",
    "\n",
    "def predict(params,X,yn):\n",
    "    mu = params[0]\n",
    "    pi = params[1]\n",
    "\n",
    "    (n,d) = X.shape\n",
    "    pred_matrix = np.zeros((n,yn))\n",
    "   \n",
    "    #count 1-X, as X is sparse matrix\n",
    "    data_X = np.tile([1],(n,d)) - X\n",
    "    pred_matrix = np.matmul(np.log(mu),X.T) + np.matmul(np.log(1 - mu),data_X.T)\n",
    "    pred_mt = np.zeros((yn,n))\n",
    "    for i in range(yn):\n",
    "        pred_mt[i,:] = np.log(pi[i,0]) + pred_matrix[i,:]\n",
    "\n",
    "    pred = np.zeros((n,1))\n",
    "    pred[:,0] = np.argmax(pred_mt,axis=0)\n",
    "    pred = pred + 1\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "def print_top_words(params,vocab):\n",
    "    \n",
    "    mu = params[0]\n",
    "    pi = params[1]\n",
    "    x0 = mu[1,:] * (1 - mu[0,:])\n",
    "    x1 = mu[0,:] * (1 - mu[1,:])\n",
    "    alpha = np.log(x0 / x1)\n",
    "    \n",
    "    d = len(vocab)\n",
    "    alpha_idx = sorted(range(d), key=lambda k: alpha[k])\n",
    "    minnum = alpha_idx[0:20]\n",
    "    maxnum = alpha_idx[-20:]\n",
    "    min_list = []\n",
    "    max_list = []\n",
    "    for i in minnum:\n",
    "        min_list.insert(0,vocab[i])\n",
    "    for i in maxnum:\n",
    "        max_list.insert(0,vocab[i])\n",
    "    print(\"largest words are\",max_list)\n",
    "    print(\"smallest words are\",min_list)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def load_data():\n",
    "    return loadmat('news.mat')\n",
    "\n",
    "def load_vocab():\n",
    "    with open('news.vocab') as f:\n",
    "        vocab = [ x.strip() for x in f.readlines() ]\n",
    "    return vocab\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    news = load_data()\n",
    "    # 20-way classification problem\n",
    "\n",
    "    data = news['data']\n",
    "    labels = news['labels']\n",
    "    testdata = news['testdata']\n",
    "    testlabels = news['testlabels']\n",
    "    \n",
    "    data = data.toarray()\n",
    "    testdata = testdata.toarray()\n",
    "\n",
    "   \n",
    "    \n",
    "    (ntrain,dtrain) = data.shape\n",
    "    (ntest,dtest) = testdata.shape\n",
    "    \n",
    "    # 2 classes\n",
    "    indices = (labels==1) | (labels==16) | (labels==20) | (labels==17) | (labels==18) | (labels==19)  \n",
    "    indices = np.reshape(indices, ntrain)\n",
    "    data2 = data[indices,:]\n",
    "    labels2 = labels[indices]\n",
    "    labels2[(labels2==1) | (labels2==16) | (labels2==20)] = 1\n",
    "    labels2[(labels2==17) | (labels2==18) | (labels2==19)] = 2\n",
    "    \n",
    "    testindices = (testlabels==1) | (testlabels==16) | (testlabels==20) | (testlabels==17) | (testlabels==18) | (testlabels==19)\n",
    "    testindices = np.reshape(testindices, ntest)\n",
    "    testdata2 = testdata[testindices,:]\n",
    "    testlabels2 = testlabels[testindices]\n",
    "    testlabels2[(testlabels2==1) | (testlabels2==16) | (testlabels2==20)] = 1\n",
    "    testlabels2[(testlabels2==17) | (testlabels2==18) | (testlabels2==19)] = 2\n",
    "\n",
    "    vocab = load_vocab()\n",
    "    print_top_words(params2,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 classes: training error rate: 0.216257\n",
      "20 classes: test error rate: 0.376016\n",
      "2 classes: training error rate: 0.0577939\n",
      "2 classes: test error rate: 0.131383\n",
      "largest words are ['firearms', 'occupied', 'israelis', 'argic', 'serdar', 'melkonian', 'sahak', 'appressian', 'ohanus', 'villages', 'cramer', 'armenia', 'cpr', 'sdpa', 'palestine', 'optilink', 'handgun', 'firearm', 'budget', 'arabs']\n",
      "smallest words are ['prophet', 'mozumder', 'jesus', 'benedikt', 'ksand', 'alink', 'believers', 'theology', 'scriptures', 'wpd', 'solntze', 'atheist', 'livesey', 'testament', 'revelation', 'teachings', 'clh', 'atheists', 'atheism', 'athos']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def estimate_naive_bayes_classifier(X,Y,yn):\n",
    "    '''divide X into yn classes'''\n",
    "    list_x = []\n",
    "    for i in range(1,yn+1):\n",
    "        idx = [idx for idx, elem in enumerate(Y) if elem == i]\n",
    "        list_x.append(X[idx,:])\n",
    "\n",
    "    '''count mu and pi'''\n",
    "    n,d = X.shape\n",
    "    mu = np.zeros((yn,d))\n",
    "    pi = np.zeros((yn,1))\n",
    "\n",
    "    for i in range(0,yn):\n",
    "        darray = list_x[i]\n",
    "        sumx = np.sum(darray, axis = 0)\n",
    "        piy = darray.shape[0]\n",
    "        mu[i,:] = np.divide((1+sumx),(2+piy))\n",
    "        pi[i,0] = np.divide(float(piy),float(yn))\n",
    "\n",
    "    return (mu,pi)\n",
    "\n",
    "\n",
    "def predict(params,X,yn):\n",
    "    mu = params[0]\n",
    "    pi = params[1]\n",
    "\n",
    "    (n,d) = X.shape\n",
    "    pred_matrix = np.zeros((n,yn))\n",
    "   \n",
    "    #count 1-X, as X is sparse matrix\n",
    "    data_X = np.tile([1],(n,d)) - X\n",
    "    pred_matrix = np.matmul(np.log(mu),X.T) + np.matmul(np.log(1 - mu),data_X.T)\n",
    "    pred_mt = np.zeros((yn,n))\n",
    "    for i in range(yn):\n",
    "        pred_mt[i,:] = np.log(pi[i,0]) + pred_matrix[i,:]\n",
    "\n",
    "    pred = np.zeros((n,1))\n",
    "    pred[:,0] = np.argmax(pred_mt,axis=0)\n",
    "    pred = pred + 1\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "def print_top_words(params,vocab):\n",
    "    \n",
    "    mu = params[0]\n",
    "    x0 = mu[1,:] * (1 - mu[0,:])\n",
    "    x1 = mu[0,:] * (1 - mu[1,:])\n",
    "    alpha = np.log(x0 / x1)\n",
    "    \n",
    "    d = len(vocab)\n",
    "    alpha_idx = sorted(range(d), key=lambda k: alpha[k])\n",
    "    minnum = alpha_idx[0:20]\n",
    "    maxnum = alpha_idx[-20:]\n",
    "    min_list = []\n",
    "    max_list = []\n",
    "    for i in minnum:\n",
    "        min_list.insert(0,vocab[i])\n",
    "    for i in maxnum:\n",
    "        max_list.insert(0,vocab[i])\n",
    "    print(\"largest words are\",max_list)\n",
    "    print(\"smallest words are\",min_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    return loadmat('news.mat')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_vocab():\n",
    "    with open('news.vocab') as f:\n",
    "        vocab = [ x.strip() for x in f.readlines() ]\n",
    "    return vocab\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    news = load_data()\n",
    "    # 20-way classification problem\n",
    "\n",
    "    data = news['data']\n",
    "    labels = news['labels']\n",
    "    testdata = news['testdata']\n",
    "    testlabels = news['testlabels']\n",
    "    \n",
    "    data = data.toarray()\n",
    "    testdata = testdata.toarray()\n",
    "#     print(data.shape)\n",
    "#     print(labels.shape)\n",
    "#     print(params.shape)\n",
    "    params = estimate_naive_bayes_classifier(data,labels,20)\n",
    "    pred = predict(params,data,20) # predictions on training data\n",
    "    testpred = predict(params,testdata,20) # predictions on test data\n",
    "\n",
    "    print('20 classes: training error rate: %g' % np.mean(pred != labels))\n",
    "    print('20 classes: test error rate: %g' % np.mean(testpred != testlabels))\n",
    "    \n",
    "    (ntrain,dtrain) = data.shape\n",
    "    (ntest,dtest) = testdata.shape\n",
    "    \n",
    "    # 2 classes\n",
    "    indices = (labels==1) | (labels==16) | (labels==20) | (labels==17) | (labels==18) | (labels==19)  \n",
    "    indices = np.reshape(indices, ntrain)\n",
    "    data2 = data[indices,:]\n",
    "    labels2 = labels[indices]\n",
    "    labels2[(labels2==1) | (labels2==16) | (labels2==20)] = 1\n",
    "    labels2[(labels2==17) | (labels2==18) | (labels2==19)] = 2\n",
    "    \n",
    "    testindices = (testlabels==1) | (testlabels==16) | (testlabels==20) | (testlabels==17) | (testlabels==18) | (testlabels==19)\n",
    "    testindices = np.reshape(testindices, ntest)\n",
    "    testdata2 = testdata[testindices,:]\n",
    "    testlabels2 = testlabels[testindices]\n",
    "    testlabels2[(testlabels2==1) | (testlabels2==16) | (testlabels2==20)] = 1\n",
    "    testlabels2[(testlabels2==17) | (testlabels2==18) | (testlabels2==19)] = 2\n",
    "\n",
    "    params2 = estimate_naive_bayes_classifier(data2,labels2,2)\n",
    "    pred2 = predict(params2,data2,2) # predictions on training data\n",
    "    testpred2 = predict(params2,testdata2,2) # predictions on test data\n",
    "    print('2 classes: training error rate: %g' % np.mean(pred2 != labels2))\n",
    "    print('2 classes: test error rate: %g' % np.mean(testpred2 != testlabels2))\n",
    "\n",
    "    vocab = load_vocab()\n",
    "    print_top_words(params2,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t0.11477\t0.00392964\n",
      "2000\t0.08941\t0.0035728\n",
      "4000\t0.06976\t0.00168416\n",
      "8000\t0.0555\t0.001253\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import print_function\n",
    "from scipy.io import loadmat\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def nn(X,Y,test):\n",
    "\n",
    "    x2 = np.square(X).sum(axis = 1)                                     \n",
    "    xt = np.dot(test,X.T)\n",
    "    t2 = np.transpose(np.square(test).sum(axis = 1)[np.newaxis]) \n",
    "    dist = x2 - 2*xt + t2\n",
    "    preds = Y[np.argmin(dist, axis = 1)]\n",
    "    return preds\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ocr = loadmat('ocr.mat')\n",
    "    num_trials = 10\n",
    "    mean_error = []\n",
    "    std_err = []\n",
    "    num = [1000,2000,4000,8000]\n",
    "    for n in [ 1000, 2000, 4000, 8000 ]:\n",
    "        test_err = np.zeros(num_trials)\n",
    "        for trial in range(num_trials):\n",
    "            sel = sample(range(len(ocr['data'].astype('float'))),n)\n",
    "            preds = nn(ocr['data'].astype('float')[sel], ocr['labels'][sel], ocr['testdata'].astype('float'))\n",
    "            test_err[trial] = np.mean(preds != ocr['testlabels'])\n",
    "        print(\"%d\\t%g\\t%g\" % (n,np.mean(test_err),np.std(test_err)))\n",
    "        mean_error.append(np.mean(test_err))\n",
    "        std_err.append(np.std(test_err))\n",
    "        \n",
    "    plt.scatter(num,mean_error)\n",
    "    plt.errorbar(num,mean_error,std_err)\n",
    "    plt.title('Learning Curve Plot')\n",
    "    plt.xlabel('n')\n",
    "    plt.ylabel('Error rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
